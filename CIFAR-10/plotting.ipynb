{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import IPython\n",
    "import progressbar\n",
    "from time import sleep\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf \n",
    "tf.autograph.set_verbosity(1)\n",
    "import pickle\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_rank(W, thr):\n",
    "    [Utemp,S,V] = np.linalg.svd(W)\n",
    "    rank = np.count_nonzero(S > thr)\n",
    "    return rank\n",
    "\n",
    "\n",
    "def decimal_str(x: float, decimals: int = 10) -> str:\n",
    "    return format(x, f\".{decimals}f\").lstrip().rstrip('0')\n",
    "\n",
    "\n",
    "def get_flat_layer_1(x, conv1_w, conv1_b, conv2_w ,conv2_b, fc1_w, fc1_b, fc2_w, fc2_b, fc3_w, fc3_b):\n",
    "\tconv1 = tf.nn.conv2d(x,conv1_w, strides = [1,1,1,1], padding = 'VALID') + conv1_b \n",
    "\t# TODO: Activation.\n",
    "\tconv1 = tf.nn.relu(conv1)\n",
    "\t# Pooling Layer. Input = 28x28x1. Output = 14x14x6.\n",
    "\tpool_1 = tf.nn.max_pool(conv1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "\t# TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "\tconv2 = tf.nn.conv2d(pool_1, conv2_w, strides = [1,1,1,1], padding = 'VALID') + conv2_b\n",
    "\t# TODO: Activation.\n",
    "\tconv2 = tf.nn.relu(conv2)# TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "\tpool_2 = tf.nn.max_pool(conv2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "\t# TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    "\tfc1_temp = flatten(pool_2)\n",
    "\t# TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "\tfc1 = tf.matmul(fc1_temp, fc1_w) + fc1_b\n",
    "\t# TODO: Activation.\n",
    "\tfc1 = tf.nn.relu(fc1)\n",
    "\t# TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "\tfc2 = tf.matmul(fc1, fc2_w) + fc2_b\n",
    "\t# TODO: Activation.\n",
    "\tfc2 = tf.nn.relu(fc2)\n",
    "\t# TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "\tlogits = tf.matmul(fc2, fc3_w) + fc3_b\n",
    "\tsess = tf.Session()\n",
    "\treturn sess.run(fc1_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.set_random_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "conv1_w = np.loadtxt('data/conv1_w', delimiter=',').reshape([5,5,1,6])\n",
    "conv1_b = np.loadtxt('data/conv1_b',  delimiter=',')\n",
    "conv2_w = np.loadtxt('data/conv2_w', delimiter=',').reshape([5,5,6,16])\n",
    "conv2_b = np.loadtxt('data/conv2_b', delimiter=',')\n",
    "fc1_w = np.loadtxt('data/fc1_w', delimiter=',')\n",
    "fc1_b = np.loadtxt('data/fc1_b', delimiter=',')\n",
    "fc2_w = np.loadtxt('data/fc2_w', delimiter=',')\n",
    "fc2_b = np.loadtxt('data/fc2_b', delimiter=',')\n",
    "fc3_w = np.loadtxt('data/fc3_w', delimiter=',')\n",
    "fc3_b = np.loadtxt('data/fc3_b', delimiter=',')\n",
    "train_x = np.loadtxt('data/train_x', delimiter=',').reshape([33600, 32, 32, 1])\n",
    "\n",
    "\n",
    "# save_layer = get_flat_layer_1(train_x, conv1_w, conv1_b, conv2_w ,conv2_b, fc1_w, fc1_b, fc2_w, fc2_b, fc3_w, fc3_b)\n",
    "# np.savetxt('data/fc1', save_layer,  delimiter=',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rank_l1_tot = []\n",
    "rank_l2_tot = []\n",
    "#N_List = [200, 400, 800]\n",
    "for N in [200]:\n",
    "\tcompr_acc_train = []\n",
    "\tcompr_acc_test = []\n",
    "\tnotes_filename_1 = 'Lenet_layer1_Constr_low_rank_N_' + str(N) + '_notes_python'\n",
    "\tnotes_1 = np.loadtxt('data/' + notes_filename_1 + '.txt', delimiter=',')\n",
    "\tn_notes_1, _ = notes_1.shape\n",
    "\tepsilon_1 = notes_1[:, 0]\n",
    "\tranks_1 = notes_1[:, 1]\n",
    "\n",
    "\tnotes_filename_2 = 'Lenet_layer2_Constr_low_rank_N_' + str(N) + '_notes_python'\n",
    "\tnotes_2 = np.loadtxt('data/' + notes_filename_2 + '.txt', delimiter=',')\n",
    "\tn_notes_2, _ = notes_2.shape\n",
    "\tepsilon_2 = notes_2[:, 0]\n",
    "\tranks_2 = notes_2[:, 1]\n",
    "\trank_l1 = []\n",
    "\trank_l2 = []\n",
    "\tbar_cnt = 0\n",
    "\tfor eps in epsilon_2[:22]:\n",
    "\t\t\n",
    "\t\tfile_name_1 = 'Lenet_layer1_Constr_Low_Rank_N_' + str(N) + '_Eps_' + str(decimal_str(eps)).replace('.', '')\n",
    "\t\tfile_name_2 = 'Lenet_layer2_Constr_Low_Rank_N_' + str(N) + '_Eps_' + str(decimal_str(eps)).replace('.', '')\n",
    "\t\t# load first layer\n",
    "\t\tweight_lr1 = np.loadtxt('data/'+ file_name_1 + '.txt', delimiter=',')\n",
    "\t\tr1 = get_rank(weight_lr1, 0.001)\n",
    "\t\trank_l1.append(r1)\n",
    "\t\t# threshold singular values for real low rank\n",
    "\t\t\n",
    "\t\t# load second layer\n",
    "\t\tweight_lr2 = np.loadtxt('data/'+ file_name_2 + '.txt', delimiter=',')\n",
    "\t\tr2 = get_rank(weight_lr2, 0.001)\n",
    "\t\trank_l2.append(r2)\n",
    "\n",
    "\n",
    "\t\t# acc_temp = compression_accuracy(train_x, train_labels, conv1_w, conv1_b, conv2_w ,conv2_b, weight_lr1, fc1_b, weight_lr2, fc2_b, fc3_w, fc3_b)\n",
    "\t\t# compr_acc_train.append(acc_temp)\n",
    "\t\t# acc_temp = compression_accuracy(test_x, test_labels, conv1_w, conv1_b, conv2_w ,conv2_b, weight_lr1, fc1_b, weight_lr2, fc2_b, fc3_w, fc3_b)\n",
    "\t\t# compr_acc_test.append(acc_temp)\n",
    "\t\t\n",
    "\n",
    "\t\n",
    "\n",
    "\trank_l1_tot.append(rank_l1)\n",
    "\trank_l2_tot.append(rank_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tot_params = 400*120 + 120 + 120*84 + 84\n",
    "\n",
    "# # Result Second Run:\n",
    "# N_200 = [0.97011906, 0.9703571, 0.9714286, 0.9715476, 0.9702381, 0.9704762, 0.9691667, 0.9675, 0.9647619, 0.96190476, 0.9588095, 0.9475, 0.91119045, 0.6875, 0.108571425, 0.108571425, 0.108571425, 0.108571425, 0.108571425]\n",
    "# N_400 = [0.98, 0.98035717, 0.97964287, 0.97964287, 0.97892857, 0.97821426, 0.9775, 0.9765476, 0.9747619, 0.97309524, 0.97011906, 0.9597619, 0.9167857, 0.7890476, 0.108571425, 0.108571425, 0.108571425, 0.108571425, 0.108571425]\n",
    "# N_800 = [0.98214287, 0.98261905, 0.98261905, 0.9829762, 0.9830952, 0.98261905, 0.98202384, 0.9809524, 0.9790476, 0.97833335, 0.97619045, 0.9695238, 0.95464283, 0.84011906, 0.108571425, 0.108571425, 0.108571425, 0.108571425, 0.108571425]\n",
    "\n",
    "\n",
    "params_200 = []\n",
    "params_400 = []\n",
    "params_800 = []\n",
    "\n",
    "for i in range(len(rank_l1_tot[0])):\n",
    "\ttemp_params_200 = 400*rank_l1_tot[0][i] + rank_l1_tot[0][i]*120 + 120 + 120*rank_l2_tot[0][i] + rank_l2_tot[0][i]*84 + 84\n",
    "# \ttemp_params_400 = 400*rank_l1_tot[1][i] + rank_l1_tot[1][i]*120 + 120 + 120*rank_l2_tot[1][i] + rank_l2_tot[1][i]*84 + 84\n",
    "# \ttemp_params_800 = 400*rank_l1_tot[2][i] + rank_l1_tot[2][i]*120 + 120 + 120*rank_l2_tot[2][i] + rank_l2_tot[2][i]*84 + 84\n",
    "\tparams_200.append(temp_params_200)\n",
    "# \tparams_400.append(temp_params_400)\n",
    "# \tparams_800.append(temp_params_800)\n",
    "\n",
    "\n",
    "# NLR_test_acc = np.array(NLR_test_acc)\n",
    "# NLR_size = np.array(NLR_size)\n",
    "# LR_test_acc = np.array(LR_test_acc)\n",
    "# LR_size = np.array(LR_size)\n",
    "# LDR_test_acc = np.array(LDR_test_acc)\n",
    "# LDR_size = np.array(LDR_size)\n",
    "params_200 = np.array(params_200)\n",
    "# params_400 = np.array(params_400)\n",
    "# params_800 = np.array(params_800)\n",
    "\n",
    "#N_200 = np.array(N_200)\n",
    "# N_400 = np.array(N_400)\n",
    "# N_800 = np.array(N_800)\n",
    "# plt.plot(LDR_size*100/orig_size, LDR_test_acc/orig_test_acc,'r-*')\n",
    "orig_test_acc = 0.9828\n",
    "\n",
    "###################### \n",
    "# get the tuned results\n",
    "res_dict = pickle.load(open( \"data/MNIST_FT_dict_epochs.pkl\", \"rb\" ))\n",
    "res_dict_noepoch = pickle.load(open( \"data/MNIST_FT_dict_no_epochs.pkl\", \"rb\" ))\n",
    "\n",
    "\n",
    "\n",
    "# notes_filename_1 = 'Lenet_layer1_Constr_low_rank_N_' + str(N) + '_notes_python'\n",
    "# notes_1 = np.loadtxt('data/' + notes_filename_1 + '.txt', delimiter=',')\n",
    "# n_notes_1, _ = notes_1.shape\n",
    "# epsilon_1 = notes_1[:, 0]\n",
    "# ranks_1 = notes_1[:, 1]\n",
    "\n",
    "# notes_filename_2 = 'Lenet_layer2_Constr_low_rank_N_' + str(N) + '_notes_python'\n",
    "# notes_2 = np.loadtxt('data/' + notes_filename_2 + '.txt', delimiter=',')\n",
    "# epsilon_2 = notes_2[:, 0]\n",
    "# ranks_2 = notes_2[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "N_200_ep0 = []\n",
    "N_200_ep5 = []\n",
    "N_200_ep10 = []\n",
    "N_200_ep20 = []\n",
    "# N_400_ep5 = []\n",
    "# N_400_ep10 = []\n",
    "# N_400_ep20 = []\n",
    "# N_800_ep5 = []\n",
    "# N_800_ep10 = []\n",
    "# N_800_ep20 = []\n",
    "\n",
    "for eps in epsilon_1[:22]:\n",
    "    N_200_ep0.append(res_dict_noepoch[(200, eps)])\n",
    "    N_200_ep5.append(res_dict[(200, 1, eps)])\n",
    "    N_200_ep10.append(res_dict[(200,2, eps)])\n",
    "    N_200_ep20.append(res_dict[(200,5, eps)])\n",
    "# \tN_400_ep5.append(res_dict[(1, 400, eps)])\n",
    "# \tN_400_ep10.append(res_dict[(2, 400, eps)])\n",
    "# \tN_400_ep20.append(res_dict[(5, 400, eps)])\n",
    "# \tN_800_ep5.append(res_dict[(1, 800, eps)])\n",
    "# \tN_800_ep10.append(res_dict[(2, 800, eps)])\n",
    "# \tN_800_ep20.append(res_dict[(5, 800, eps)])\n",
    "######################\n",
    "\n",
    "N_200_ep0 = np.array(N_200_ep0)\n",
    "N_200_ep5 = np.array(N_200_ep5)\n",
    "N_200_ep10 = np.array(N_200_ep10)\n",
    "N_200_ep20 = np.array(N_200_ep20)\n",
    "# N_400_ep5 = np.array(N_400_ep5)\n",
    "# N_400_ep10 = np.array(N_400_ep10)\n",
    "# N_400_ep20 = np.array(N_400_ep20)\n",
    "# N_800_ep5 = np.array(N_800_ep5)\n",
    "# N_800_ep10 = np.array(N_800_ep10)\n",
    "# N_800_ep20 = np.array(N_800_ep20)\n",
    "\n",
    "\n",
    "\n",
    "# plt.rcParams.update({\n",
    "#     \"text.usetex\": True})\n",
    "\n",
    "# NLR_test_acc = np.array(NLR_test_acc)\n",
    "# NLR_size = np.array(NLR_size)\n",
    "# LR_test_acc = np.array(LR_test_acc)\n",
    "# LR_size = np.array(LR_size)\n",
    "# # LDR_test_acc = np.array(LDR_test_acc)\n",
    "# # LDR_size = np.array(LDR_size)\n",
    "\n",
    "# # plt.plot(LDR_size*100/orig_size, LDR_test_acc/orig_test_acc,'r-*')\n",
    "\n",
    "# plt.plot(LR_size*100/orig_size, LR_test_acc/orig_test_acc,'b-o', label=r'\\textrm{Constrained Low Rank}')\n",
    "# plt.plot(NLR_size*100/orig_size, NLR_test_acc/orig_test_acc,'g--s', label=r'\\textrm{Low Rank}')\n",
    "\n",
    "# plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[0]/orig_test_acc,'r--s', label=r'\\textrm{Low Rank (Ep = 5)}')\n",
    "# plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[1]/orig_test_acc,'y--s', label=r'\\textrm{Low Rank (Ep = 10)}')\n",
    "# # plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[2]/orig_test_acc,'c--s', label=r'\\textrm{Low Rank (Ep = 15))}')\n",
    "# # plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[3]/orig_test_acc,'k--s', label=r'\\textrm{Low Rank (Ep = 20))}')\n",
    "\n",
    "\n",
    "# plt.xlabel(r'$\\textrm{Size Percentage}$', fontsize='x-large')\n",
    "# plt.ylabel(r'$\\frac{\\textrm{Accuracy Compressed}}{\\textrm{Accuracy Original}}$',fontsize='x-large') \n",
    "# plt.legend(loc=4)\n",
    "\n",
    "# plt.title(r'\\textrm{Spiral Dataset}', fontsize='x-large')\n",
    "# plt.autoscale()\n",
    "# plt.ylim([0.55, 1.04])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('Spiral_N_200_Compression_plot_FT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tot_params = 400*120 + 120 + 120*84 + 84\n",
    "\n",
    "# # # Result Second Run:\n",
    "# # N_200 = [0.97011906, 0.9703571, 0.9714286, 0.9715476, 0.9702381, 0.9704762, 0.9691667, 0.9675, 0.9647619, 0.96190476, 0.9588095, 0.9475, 0.91119045, 0.6875, 0.108571425, 0.108571425, 0.108571425, 0.108571425, 0.108571425]\n",
    "# # N_400 = [0.98, 0.98035717, 0.97964287, 0.97964287, 0.97892857, 0.97821426, 0.9775, 0.9765476, 0.9747619, 0.97309524, 0.97011906, 0.9597619, 0.9167857, 0.7890476, 0.108571425, 0.108571425, 0.108571425, 0.108571425, 0.108571425]\n",
    "# # N_800 = [0.98214287, 0.98261905, 0.98261905, 0.9829762, 0.9830952, 0.98261905, 0.98202384, 0.9809524, 0.9790476, 0.97833335, 0.97619045, 0.9695238, 0.95464283, 0.84011906, 0.108571425, 0.108571425, 0.108571425, 0.108571425, 0.108571425]\n",
    "\n",
    "\n",
    "# params_200 = []\n",
    "# params_400 = []\n",
    "# params_800 = []\n",
    "\n",
    "# for i in range(len(rank_l1_tot[0])):\n",
    "# \ttemp_params_200 = 400*rank_l1_tot[0][i] + rank_l1_tot[0][i]*120 + 120 + 120*rank_l2_tot[0][i] + rank_l2_tot[0][i]*84 + 84\n",
    "# # \ttemp_params_400 = 400*rank_l1_tot[1][i] + rank_l1_tot[1][i]*120 + 120 + 120*rank_l2_tot[1][i] + rank_l2_tot[1][i]*84 + 84\n",
    "# # \ttemp_params_800 = 400*rank_l1_tot[2][i] + rank_l1_tot[2][i]*120 + 120 + 120*rank_l2_tot[2][i] + rank_l2_tot[2][i]*84 + 84\n",
    "# \tparams_200.append(temp_params_200)\n",
    "# # \tparams_400.append(temp_params_400)\n",
    "# # \tparams_800.append(temp_params_800)\n",
    "\n",
    "\n",
    "# # NLR_test_acc = np.array(NLR_test_acc)\n",
    "# # NLR_size = np.array(NLR_size)\n",
    "# # LR_test_acc = np.array(LR_test_acc)\n",
    "# # LR_size = np.array(LR_size)\n",
    "# # LDR_test_acc = np.array(LDR_test_acc)\n",
    "# # LDR_size = np.array(LDR_size)\n",
    "# params_200 = np.array(params_200)\n",
    "# # params_400 = np.array(params_400)\n",
    "# # params_800 = np.array(params_800)\n",
    "\n",
    "# # N_400 = np.array(N_400)\n",
    "# # N_800 = np.array(N_800)\n",
    "# # plt.plot(LDR_size*100/orig_size, LDR_test_acc/orig_test_acc,'r-*')\n",
    "# orig_test_acc = 0.9828\n",
    "\n",
    "# ###################### \n",
    "# # get the tuned results\n",
    "# res_dict = pickle.load(open( \"data/MNIST_FT_dict_epochs.pkl\", \"rb\" ))\n",
    "\n",
    "\n",
    "\n",
    "# # notes_filename_1 = 'Lenet_layer1_Constr_low_rank_N_' + str(N) + '_notes_python'\n",
    "# # notes_1 = np.loadtxt('data/' + notes_filename_1 + '.txt', delimiter=',')\n",
    "# # n_notes_1, _ = notes_1.shape\n",
    "# # epsilon_1 = notes_1[:, 0]\n",
    "# # ranks_1 = notes_1[:, 1]\n",
    "\n",
    "# # notes_filename_2 = 'Lenet_layer2_Constr_low_rank_N_' + str(N) + '_notes_python'\n",
    "# # notes_2 = np.loadtxt('data/' + notes_filename_2 + '.txt', delimiter=',')\n",
    "# # epsilon_2 = notes_2[:, 0]\n",
    "# # ranks_2 = notes_2[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# N_200_ep5 = []\n",
    "# N_200_ep10 = []\n",
    "# N_200_ep20 = []\n",
    "# # N_400_ep5 = []\n",
    "# # N_400_ep10 = []\n",
    "# # N_400_ep20 = []\n",
    "# # N_800_ep5 = []\n",
    "# # N_800_ep10 = []\n",
    "# # N_800_ep20 = []\n",
    "\n",
    "# for eps in epsilon_1[:22]:\n",
    "# \tN_200_ep5.append(res_dict[(200, 1, eps)])\n",
    "# \tN_200_ep10.append(res_dict[(200,2, eps)])\n",
    "# \tN_200_ep20.append(res_dict[(200,5, eps)])\n",
    "# # \tN_400_ep5.append(res_dict[(1, 400, eps)])\n",
    "# # \tN_400_ep10.append(res_dict[(2, 400, eps)])\n",
    "# # \tN_400_ep20.append(res_dict[(5, 400, eps)])\n",
    "# # \tN_800_ep5.append(res_dict[(1, 800, eps)])\n",
    "# # \tN_800_ep10.append(res_dict[(2, 800, eps)])\n",
    "# # \tN_800_ep20.append(res_dict[(5, 800, eps)])\n",
    "# ######################\n",
    "\n",
    "\n",
    "# N_200_ep5 = np.array(N_200_ep5)\n",
    "# N_200_ep10 = np.array(N_200_ep10)\n",
    "# N_200_ep20 = np.array(N_200_ep20)\n",
    "# # N_400_ep5 = np.array(N_400_ep5)\n",
    "# # N_400_ep10 = np.array(N_400_ep10)\n",
    "# # N_400_ep20 = np.array(N_400_ep20)\n",
    "# # N_800_ep5 = np.array(N_800_ep5)\n",
    "# # N_800_ep10 = np.array(N_800_ep10)\n",
    "# # N_800_ep20 = np.array(N_800_ep20)\n",
    "\n",
    "\n",
    "\n",
    "# # plt.rcParams.update({\n",
    "# #     \"text.usetex\": True})\n",
    "\n",
    "# # NLR_test_acc = np.array(NLR_test_acc)\n",
    "# # NLR_size = np.array(NLR_size)\n",
    "# # LR_test_acc = np.array(LR_test_acc)\n",
    "# # LR_size = np.array(LR_size)\n",
    "# # # LDR_test_acc = np.array(LDR_test_acc)\n",
    "# # # LDR_size = np.array(LDR_size)\n",
    "\n",
    "# # # plt.plot(LDR_size*100/orig_size, LDR_test_acc/orig_test_acc,'r-*')\n",
    "\n",
    "# # plt.plot(LR_size*100/orig_size, LR_test_acc/orig_test_acc,'b-o', label=r'\\textrm{Constrained Low Rank}')\n",
    "# # plt.plot(NLR_size*100/orig_size, NLR_test_acc/orig_test_acc,'g--s', label=r'\\textrm{Low Rank}')\n",
    "\n",
    "# # plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[0]/orig_test_acc,'r--s', label=r'\\textrm{Low Rank (Ep = 5)}')\n",
    "# # plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[1]/orig_test_acc,'y--s', label=r'\\textrm{Low Rank (Ep = 10)}')\n",
    "# # # plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[2]/orig_test_acc,'c--s', label=r'\\textrm{Low Rank (Ep = 15))}')\n",
    "# # # plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[3]/orig_test_acc,'k--s', label=r'\\textrm{Low Rank (Ep = 20))}')\n",
    "\n",
    "\n",
    "# # plt.xlabel(r'$\\textrm{Size Percentage}$', fontsize='x-large')\n",
    "# # plt.ylabel(r'$\\frac{\\textrm{Accuracy Compressed}}{\\textrm{Accuracy Original}}$',fontsize='x-large') \n",
    "# # plt.legend(loc=4)\n",
    "\n",
    "# # plt.title(r'\\textrm{Spiral Dataset}', fontsize='x-large')\n",
    "# # plt.autoscale()\n",
    "# # plt.ylim([0.55, 1.04])\n",
    "# # plt.tight_layout()\n",
    "# # plt.savefig('Spiral_N_200_Compression_plot_FT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n",
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({\"text.usetex\": True})\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, sharex=True, sharey=True)\n",
    "#fig.suptitle('Sharing both axes')\n",
    "\n",
    "\n",
    "axs[0].plot(params_200*100/tot_params, N_200_ep0/orig_test_acc,'b-o', label=r'$N=200$')\n",
    "# axs[1].plot(params_400[:-5]*100/tot_params, N_400[:-5]/orig_test_acc,'b-o', label=r'$N=400$')\n",
    "# axs[2].plot(params_800[:-5]*100/tot_params, N_800[:-5]/orig_test_acc,'b-o', label=r'$N=800$')\n",
    "\n",
    "axs[0].plot(params_200*100/tot_params, N_200_ep5/orig_test_acc,'r--o', label=r'$epoch 5$')\n",
    "axs[0].plot(params_200*100/tot_params, N_200_ep10/orig_test_acc,'g--o', label=r'$epoch 10$')\n",
    "axs[0].plot(params_200*100/tot_params, N_200_ep20/orig_test_acc,'k--o', label=r'$epoch 20$')\n",
    "\n",
    "# axs[1].plot(params_400[:-5]*100/tot_params, N_400_ep5[:-5]/orig_test_acc,'r--o', label=r'$epoch 5$')\n",
    "# axs[1].plot(params_400[:-5]*100/tot_params, N_400_ep10[:-5]/orig_test_acc,'g--o', label=r'$epoch 10$')\n",
    "# axs[1].plot(params_400[:-5]*100/tot_params, N_400_ep20[:-5]/orig_test_acc,'k--o', label=r'$epoch 20$')\n",
    "\n",
    "# axs[2].plot(params_800[:-5]*100/tot_params, N_800_ep5[:-5]/orig_test_acc,'r--o', label=r'$epoch 5$')\n",
    "# axs[2].plot(params_800[:-5]*100/tot_params, N_800_ep10[:-5]/orig_test_acc,'g--o', label=r'$epoch 10$')\n",
    "# axs[2].plot(params_800[:-5]*100/tot_params, N_800_ep20[:-5]/orig_test_acc,'k--o', label=r'$epoch 20$')\n",
    "#plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[1]/orig_test_acc,'y--s', label=r'\\textrm{Low Rank (Ep = 10)}')\n",
    "# plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[2]/orig_test_acc,'c--s', label=r'\\textrm{Low Rank (Ep = 15))}')\n",
    "# plt.plot(NLR_size*100/orig_size, LR_FT_test_acc_total[3]/orig_test_acc,'k--s', label=r'\\textrm{Low Rank (Ep = 20))}')\n",
    "plt.xlabel(r'$\\textrm{Size Percentage}$', fontsize='x-large')\n",
    "# axs[1].ylabel(r'$\\frac{\\textrm{Accuracy Compressed}}{\\textrm{Accuracy Original}}$',fontsize='x-large') \n",
    "axs[0].legend(loc=4)\n",
    "axs[1].legend(loc=4)\n",
    "axs[2].legend(loc=4)\n",
    "# axs[0].set_xlim([0.8, 1.02])\n",
    "# axs[1].set_xlim([0.8, 1.02])\n",
    "# axs[2].set_xlim([0.8, 1.02])\n",
    "#plt.title(r'\\textrm{MNIST Dataset}', fontsize='x-large')\n",
    "# fig.text(0.5, 0.8, 'common X', ha='center')\n",
    "# fig.text(0.0, 0.5, 'common Y', va='center', rotation='vertical')\n",
    "\n",
    "plt.autoscale()\n",
    "#plt.ylim([0.65, 1.04])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('MNSIT_Compression_plot_FT')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "IPython.embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
